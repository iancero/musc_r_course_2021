[["multilevel-models.html", "4 Multilevel Models 4.1 Steps 1 &amp; 2 - Import and clean the data 4.2 Steps 3 &amp; 4 - Fit the model and summarize it 4.3 Logistic multilevel models", " 4 Multilevel Models In a multilevel model, we try to account not only for group-level variation, but individual variation as well. As a reminder, the way that we do this is by proposing: There is an overall slope and intercept for our regression model, just like in a traditional linear regression. But, there might be some variation from person to person or day to day in the value of that slope, intercept, or both. You can think of this like it being generally true that sleep loss leads to decreased mood the next day, but for some people it is worse than others (variable slopes). Alternatively, you might think the damage done by sleep loss is roughly the same from person to person - or perhaps that an intervention is roughly as effective for all people - but that different people start with varying degrees of sleep lost (variable intercepts). Lastly, you might think both. The trick to remember is that we are just specifying a traditional regression, plus allowing some of its parameters to be slightly different from person to person. 4.1 Steps 1 &amp; 2 - Import and clean the data Again to maximize comparability with previous chapters on regression techniques, well use the same KSADS ABCD dataset. library(tidyverse) read_abcd_quietly &lt;- function(file_path){ suppressMessages( expr = read_delim(file_path, delim = &#39;\\t&#39;) %&gt;% filter(row_number() != 1) %&gt;% type_convert()) } df &lt;- read_abcd_quietly(&#39;data/abcd_lpksad01.txt&#39;) But along the way, it is important to note that this is a longitudinal dataset with many participants providing multiple data points to us. You can thus think of those data points as providing multiple pieces of information for each person, which we can use to estimate (for example) their own personal intercept in a multilevel model. df &lt;- df %&gt;% select( id = src_subject_id, age = interview_age, sex, grade_drop = kbi_p_c_drop_in_grades_l, grades = kbi_p_grades_in_school_l) %&gt;% group_by(id) %&gt;% arrange(age) %&gt;% mutate( age = floor(age / 12), sex = factor(sex, levels = c(&#39;M&#39;, &#39;F&#39;)), time = row_number(), n_timepoints = max(time), grade_drop = factor(grade_drop, levels = c(1, 2), labels = c(&#39;yes&#39;, &#39;no&#39;))) %&gt;% ungroup() %&gt;% filter(grades %in% 1:5) %&gt;% select(id, age, sex, grades, grade_drop, time) 4.2 Steps 3 &amp; 4 - Fit the model and summarize it As we saw with logistic regression, Rs regression-centric statistical framework makes transition to a new type of regression easy for us to think about: almost everything is the same, we just need to tweak a few specifics. The first thing to note is that well need to load the lme4 package, which contains a function to fit a multilevel model. Next, we use the lmer() function to fit the model, rather than the traditional lm() for a classic linear regression. After that, the last obvious change we need to make is that we need to tell R which parameters we want to vary and what our nesting structure is. Fortunately, that is pretty easy too. We just add it to our regression formula like this + (params_to_vary | vary_by_what). As you can see below, the randomly varying part of our model is specified as (1 | id). Because 1 is Rs indicator for an intercept and id is our datasets variable indicating which person we are talking about (remember each ID will have multiple timepoints), this specification will produce a regression where the slope stays constant for everyone, BUT everyone has their own special intercept (i.e.Â a random intercept only model). library(lme4) fit &lt;- lmer( formula = grades ~ age + sex + (1 | id), data = df) summary(fit) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;] ## Formula: grades ~ age + sex + (1 | id) ## Data: df ## ## REML criterion at convergence: 50990.9 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -4.3199 -0.3357 -0.1901 0.2137 5.2364 ## ## Random effects: ## Groups Name Variance Std.Dev. ## id (Intercept) 0.4181 0.6466 ## Residual 0.2304 0.4800 ## Number of obs: 24771, groups: id, 10301 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 1.654e+00 4.460e-02 2.018e+04 37.089 &lt; 2e-16 *** ## age 1.121e-02 3.846e-03 1.888e+04 2.915 0.00357 ** ## sexF -2.006e-01 1.424e-02 1.013e+04 -14.088 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) age ## age -0.975 ## sexF -0.160 0.008 As you can see, the output is again quite similar to the regular lm() output. However, there are two twists. Because we have a random intercept, the intercept now has a group-level mean (under Fixed Effects) AND it has its own variance (under Random Effects). Were missing p-values! Find out how to get those below. 4.2.1 Where are my p-values? Multilevel models are mathematically complicated, under the hood. For reasons we wont go into here, there are many ways to compute their p-values and the lme4 package doesnt want to make the choice for you out of an abundance of caution. To get our p-values, we can use the lmerTest package, which will override the lmer() function to include p-values. Thus, if we run our same model again, but with lmerTest loaded we should get what we expected. library(lmerTest) fit &lt;- lmer( formula = grades ~ age + sex + (1 | id), data = df) summary(fit) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;] ## Formula: grades ~ age + sex + (1 | id) ## Data: df ## ## REML criterion at convergence: 50990.9 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -4.3199 -0.3357 -0.1901 0.2137 5.2364 ## ## Random effects: ## Groups Name Variance Std.Dev. ## id (Intercept) 0.4181 0.6466 ## Residual 0.2304 0.4800 ## Number of obs: 24771, groups: id, 10301 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 1.654e+00 4.460e-02 2.018e+04 37.089 &lt; 2e-16 *** ## age 1.121e-02 3.846e-03 1.888e+04 2.915 0.00357 ** ## sexF -2.006e-01 1.424e-02 1.013e+04 -14.088 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) age ## age -0.975 ## sexF -0.160 0.008 4.2.2 Where are my intraclass correlations (ICCs)? One measure of the strength of variation for a random effect in a multilevel model is the Intraclass Correlation Coefficient (ICC). These tell you the percentage of variation in the your estimate can be attributed to random variation from person to person. Unfortunately, lmer() doesnt compute this on its own, so we need to ask the performance package to do it for us. performance::icc(fit) ## # Intraclass Correlation Coefficient ## ## Adjusted ICC: 0.645 ## Conditional ICC: 0.635 4.3 Logistic multilevel models So far, weve fit just linear multilevel models, but note that the transition to a logistic version is the same as the transition from a traditional linear model to a traditional logistic one: lm() becomes glm(); lmer() becomes glmer() We need to specify the family of non-linear model we are using, which is again binomial Then everything else is the same. fit &lt;- glmer( formula = grade_drop ~ age + sex + (1 | id), data = df, family = &#39;binomial&#39;) summary(fit) ## Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) [ ## glmerMod] ## Family: binomial ( logit ) ## Formula: grade_drop ~ age + sex + (1 | id) ## Data: df ## ## AIC BIC logLik deviance df.resid ## 20086.6 20119.0 -10039.3 20078.6 24440 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.0384 0.2134 0.2559 0.3115 1.0890 ## ## Random effects: ## Groups Name Variance Std.Dev. ## id (Intercept) 2.064 1.437 ## Number of obs: 24444, groups: id, 10275 ## ## Fixed effects: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 5.87861 0.26782 21.950 &lt;2e-16 *** ## age -0.33012 0.02241 -14.728 &lt;2e-16 *** ## sexF 0.46215 0.05188 8.908 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) age ## age -0.985 ## sexF -0.049 -0.023 ## optimizer (Nelder_Mead) convergence code: 0 (OK) ## Model failed to converge with max|grad| = 0.00490794 (tol = 0.002, component 1) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
